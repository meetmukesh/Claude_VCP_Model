"""
Database Layer for Trading Scanner System
Professional-grade database management using SQLAlchemy
"""

from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Boolean, Text, JSON
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
from datetime import datetime
import json
import pandas as pd
from contextlib import contextmanager
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

Base = declarative_base()

# =====================================================
# DATABASE MODELS
# =====================================================

class StockUniverse(Base):
    """Master table for stock symbols"""
    __tablename__ = 'stock_universe'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), unique=True, nullable=False, index=True)
    name = Column(String(200))
    sector = Column(String(100))
    industry = Column(String(100))
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


class ScanResult(Base):
    """Stores daily scan results"""
    __tablename__ = 'scan_results'
    
    id = Column(Integer, primary_key=True)
    scan_date = Column(DateTime, nullable=False, index=True)
    symbol = Column(String(20), nullable=False, index=True)
    
    # Price Data
    current_price = Column(Float)
    price_change_pct = Column(Float)
    volume = Column(Float)
    avg_volume_20d = Column(Float)
    
    # Technical Indicators
    ma_21 = Column(Float)
    ma_50 = Column(Float)
    ma_200 = Column(Float)
    rsi_14 = Column(Float)
    atr_14 = Column(Float)
    
    # Relative Strength
    rs_3m = Column(Float)
    rs_6m = Column(Float)
    rs_composite = Column(Float)
    
    # Consolidation Metrics
    consolidation_range = Column(Float)
    consolidation_days = Column(Integer)
    volume_contraction = Column(Boolean)
    
    # VCP Metrics
    vcp_stage_1_range = Column(Float)
    vcp_stage_2_range = Column(Float)
    vcp_stage_3_range = Column(Float)
    vcp_qualified = Column(Boolean)
    
    # Resistance & Breakout
    resistance_level = Column(Float)
    distance_to_resistance_pct = Column(Float)
    near_breakout = Column(Boolean)
    
    # Stop Loss
    stop_loss = Column(Float)
    risk_pct = Column(Float)
    
    # Scoring
    total_score = Column(Float)
    filters_passed = Column(Integer)
    filter_details = Column(JSON)  # Stores which filters passed
    
    # Status
    is_qualified = Column(Boolean, default=False)
    market_regime = Column(String(20))
    
    # Metadata
    created_at = Column(DateTime, default=datetime.utcnow)
    
    def __repr__(self):
        return f"<ScanResult(symbol={self.symbol}, date={self.scan_date}, score={self.total_score})>"


class Watchlist(Base):
    """Tracks stocks in various stages of qualification"""
    __tablename__ = 'watchlist'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False, index=True)
    added_date = Column(DateTime, default=datetime.utcnow)
    last_updated = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Current Status
    current_filters_passed = Column(Integer)
    max_filters_achieved = Column(Integer)
    current_score = Column(Float)
    is_qualified = Column(Boolean, default=False)
    
    # Price Tracking
    entry_price = Column(Float)
    current_price = Column(Float)
    highest_price = Column(Float)
    stop_loss = Column(Float)
    
    # Progress Tracking
    filter_progression = Column(JSON)  # Historical filter counts
    alert_history = Column(JSON)  # Alert log
    
    # Status
    status = Column(String(20))  # 'ACTIVE', 'QUALIFIED', 'DETERIORATED', 'REMOVED'
    removal_reason = Column(String(200))
    removed_date = Column(DateTime)
    
    def __repr__(self):
        return f"<Watchlist(symbol={self.symbol}, filters={self.current_filters_passed}, status={self.status})>"


class TradingAlert(Base):
    """Stores alerts generated by the system"""
    __tablename__ = 'trading_alerts'
    
    id = Column(Integer, primary_key=True)
    alert_date = Column(DateTime, default=datetime.utcnow, index=True)
    symbol = Column(String(20), nullable=False, index=True)
    alert_type = Column(String(50))  # 'QUALIFICATION', 'FILTER_IMPROVEMENT', 'DETERIORATION', 'BREAKOUT'
    severity = Column(String(20))  # 'INFO', 'WARNING', 'CRITICAL'
    
    message = Column(Text)
    details = Column(JSON)
    
    is_read = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow)


class ScanMetadata(Base):
    """Tracks scan execution metadata"""
    __tablename__ = 'scan_metadata'
    
    id = Column(Integer, primary_key=True)
    scan_date = Column(DateTime, nullable=False, index=True)
    scan_type = Column(String(50))  # 'FULL_SCAN', 'WATCHLIST_UPDATE'
    
    # Execution Metrics
    start_time = Column(DateTime)
    end_time = Column(DateTime)
    duration_seconds = Column(Float)
    
    # Results Summary
    total_stocks_scanned = Column(Integer)
    qualified_stocks = Column(Integer)
    watchlist_additions = Column(Integer)
    alerts_generated = Column(Integer)
    
    # Market Context
    market_regime = Column(String(20))
    benchmark_change_pct = Column(Float)
    
    # Configuration Snapshot
    config_snapshot = Column(JSON)
    
    # Status
    status = Column(String(20))  # 'SUCCESS', 'FAILED', 'PARTIAL'
    error_message = Column(Text)
    
    created_at = Column(DateTime, default=datetime.utcnow)


class PriceHistory(Base):
    """Stores historical price data for backtesting and analysis"""
    __tablename__ = 'price_history'
    
    id = Column(Integer, primary_key=True)
    symbol = Column(String(20), nullable=False, index=True)
    date = Column(DateTime, nullable=False, index=True)
    
    open = Column(Float)
    high = Column(Float)
    low = Column(Float)
    close = Column(Float)
    volume = Column(Float)
    
    created_at = Column(DateTime, default=datetime.utcnow)
    
    __table_args__ = (
        # Composite index for efficient queries
        {'sqlite_autoincrement': True}
    )


# =====================================================
# DATABASE MANAGER
# =====================================================

class DatabaseManager:
    """Manages all database operations"""
    
    def __init__(self, db_url=None):
        """
        Initialize database connection
        
        Args:
            db_url: Database connection string (optional - will auto-detect)
        """
        # Auto-detect database URL from environment
        if db_url is None:
            import os
            
            # Try environment variable first (GitHub Actions)
            db_url = os.getenv('DATABASE_URL')
            
            # Try Streamlit secrets (Streamlit Cloud)
            if db_url is None:
                try:
                    import streamlit as st
                    if hasattr(st, 'secrets') and 'DATABASE_URL' in st.secrets:
                        db_url = st.secrets['DATABASE_URL']
                        logger.info("Using DATABASE_URL from Streamlit secrets")
                except:
                    pass
            
            # Fallback to SQLite for local dev
            if db_url is None:
                db_url = 'sqlite:///trading_scanner.db'
                logger.warning("Using SQLite - dev mode")
        
        # Fix postgres:// to postgresql://
        if db_url and db_url.startswith('postgres://'):
            db_url = db_url.replace('postgres://', 'postgresql://', 1)
        
        self.db_url = db_url
        
        # Log database type
        if db_url.startswith('postgresql://'):
            logger.info("âœ“ Using PostgreSQL (production)")
        
        try:
            self.engine = create_engine(db_url, echo=False, pool_pre_ping=True)
            self.Session = scoped_session(sessionmaker(bind=self.engine))
            logger.info("Database connected successfully")
        except Exception as e:
            logger.error(f"Database connection failed: {e}")
            raise
        logger.info(f"Database initialized: {db_url}")
    
    def create_tables(self):
        """Create all tables if they don't exist"""
        Base.metadata.create_all(self.engine)
        logger.info("Database tables created/verified")
    
    @contextmanager
    def session_scope(self):
        """Provide a transactional scope for database operations"""
        session = self.Session()
        try:
            yield session
            session.commit()
        except Exception as e:
            session.rollback()
            logger.error(f"Database error: {e}")
            raise
        finally:
            session.close()
    
    # =====================================================
    # STOCK UNIVERSE OPERATIONS
    # =====================================================
    
    def load_stock_universe(self, csv_path=None, df=None):
        """
        Load stock symbols from CSV or DataFrame into database
        
        Args:
            csv_path: Path to CSV file with stock symbols
            df: DataFrame with stock symbols
        
        Returns:
            Number of stocks loaded
        """
        if csv_path:
            df = pd.read_csv(csv_path)
        
        if df is None:
            raise ValueError("Either csv_path or df must be provided")
        
        with self.session_scope() as session:
            count = 0
            for _, row in df.iterrows():
                symbol = row.get('Symbol', row.get('symbol'))
                if not symbol:
                    continue
                
                # Check if exists
                existing = session.query(StockUniverse).filter_by(symbol=symbol).first()
                if not existing:
                    stock = StockUniverse(
                        symbol=symbol,
                        name=row.get('Name', row.get('name', '')),
                        sector=row.get('Sector', row.get('sector', '')),
                        industry=row.get('Industry', row.get('industry', ''))
                    )
                    session.add(stock)
                    count += 1
            
            logger.info(f"Loaded {count} new stocks into universe")
            return count
    
    def get_active_stocks(self):
        """Get list of active stock symbols"""
        with self.session_scope() as session:
            stocks = session.query(StockUniverse).filter_by(is_active=True).all()
            return [stock.symbol for stock in stocks]
    
    # =====================================================
    # SCAN RESULTS OPERATIONS
    # =====================================================
    
    def save_scan_results(self, results_df, scan_date=None):
        """
        Save scan results to database
        
        Args:
            results_df: DataFrame with scan results
            scan_date: Date of scan (defaults to now)
        
        Returns:
            Number of results saved
        """
        if scan_date is None:
            scan_date = datetime.now()
        
        with self.session_scope() as session:
            count = 0
            for _, row in results_df.iterrows():
                scan_result = ScanResult(
                    scan_date=scan_date,
                    symbol=row.get('Symbol'),
                    current_price=row.get('Current_Price'),
                    price_change_pct=row.get('Price_Change_%'),
                    volume=row.get('Volume'),
                    avg_volume_20d=row.get('Avg_Volume_20D'),
                    ma_21=row.get('MA_21'),
                    ma_50=row.get('MA_50'),
                    ma_200=row.get('MA_200'),
                    rsi_14=row.get('RSI_14'),
                    atr_14=row.get('ATR_14'),
                    rs_3m=row.get('RS_3M'),
                    rs_6m=row.get('RS_6M'),
                    rs_composite=row.get('RS_Composite'),
                    consolidation_range=row.get('Consol_Range_%'),
                    consolidation_days=row.get('Consol_Days'),
                    volume_contraction=row.get('Vol_Contraction'),
                    vcp_stage_1_range=row.get('VCP_Stage1_%'),
                    vcp_stage_2_range=row.get('VCP_Stage2_%'),
                    vcp_stage_3_range=row.get('VCP_Stage3_%'),
                    vcp_qualified=row.get('VCP_Qualified'),
                    resistance_level=row.get('Resistance'),
                    distance_to_resistance_pct=row.get('Dist_to_Resistance_%'),
                    near_breakout=row.get('Near_Breakout'),
                    stop_loss=row.get('Stop_Loss'),
                    risk_pct=row.get('Risk_%'),
                    total_score=row.get('Total_Score'),
                    filters_passed=row.get('Filters_Passed'),
                    filter_details=row.get('Filter_Details', {}),
                    is_qualified=row.get('Is_Qualified', False),
                    market_regime=row.get('Market_Regime')
                )
                session.add(scan_result)
                count += 1
            
            logger.info(f"Saved {count} scan results")
            return count
    
    def get_latest_scan_results(self, qualified_only=False):
        """Get most recent scan results"""
        with self.session_scope() as session:
            # Get latest scan date
            latest_date = session.query(ScanResult.scan_date)\
                .order_by(ScanResult.scan_date.desc())\
                .first()
            
            if not latest_date:
                return pd.DataFrame()
            
            # Get results for that date
            query = session.query(ScanResult)\
                .filter(ScanResult.scan_date == latest_date[0])
            
            if qualified_only:
                query = query.filter(ScanResult.is_qualified == True)
            
            results = query.all()
            
            # Convert to DataFrame
            return self._scan_results_to_df(results)
    
    def get_scan_results_by_date(self, start_date, end_date=None):
        """Get scan results for a date range"""
        if end_date is None:
            end_date = datetime.now()
        
        with self.session_scope() as session:
            results = session.query(ScanResult)\
                .filter(ScanResult.scan_date >= start_date)\
                .filter(ScanResult.scan_date <= end_date)\
                .order_by(ScanResult.scan_date.desc())\
                .all()
            
            return self._scan_results_to_df(results)
    
    def _scan_results_to_df(self, results):
        """Convert ScanResult objects to DataFrame"""
        if not results:
            return pd.DataFrame()
        
        data = []
        for r in results:
            data.append({
                'Scan_Date': r.scan_date,
                'Symbol': r.symbol,
                'Current_Price': r.current_price,
                'Price_Change_%': r.price_change_pct,
                'Volume': r.volume,
                'Avg_Volume_20D': r.avg_volume_20d,
                'MA_21': r.ma_21,
                'MA_50': r.ma_50,
                'MA_200': r.ma_200,
                'RSI_14': r.rsi_14,
                'ATR_14': r.atr_14,
                'RS_3M': r.rs_3m,
                'RS_6M': r.rs_6m,
                'RS_Composite': r.rs_composite,
                'Consol_Range_%': r.consolidation_range,
                'Consol_Days': r.consolidation_days,
                'Vol_Contraction': r.volume_contraction,
                'VCP_Qualified': r.vcp_qualified,
                'Resistance': r.resistance_level,
                'Dist_to_Resistance_%': r.distance_to_resistance_pct,
                'Near_Breakout': r.near_breakout,
                'Stop_Loss': r.stop_loss,
                'Risk_%': r.risk_pct,
                'Total_Score': r.total_score,
                'Filters_Passed': r.filters_passed,
                'Is_Qualified': r.is_qualified,
                'Market_Regime': r.market_regime
            })
        
        return pd.DataFrame(data)
    
    # =====================================================
    # WATCHLIST OPERATIONS
    # =====================================================
    
    def update_watchlist(self, symbol, filters_passed, score, price, stop_loss, 
                        is_qualified=False, filter_progression=None, alert=None):
        """Update or create watchlist entry"""
        with self.session_scope() as session:
            watchlist = session.query(Watchlist).filter_by(symbol=symbol).first()
            
            if not watchlist:
                # Create new entry
                watchlist = Watchlist(
                    symbol=symbol,
                    current_filters_passed=filters_passed,
                    max_filters_achieved=filters_passed,
                    current_score=score,
                    entry_price=price,
                    current_price=price,
                    highest_price=price,
                    stop_loss=stop_loss,
                    is_qualified=is_qualified,
                    status='ACTIVE',
                    filter_progression=[],
                    alert_history=[]
                )
                session.add(watchlist)
            else:
                # Update existing
                watchlist.current_filters_passed = filters_passed
                watchlist.max_filters_achieved = max(watchlist.max_filters_achieved, filters_passed)
                watchlist.current_score = score
                watchlist.current_price = price
                watchlist.highest_price = max(watchlist.highest_price or 0, price)
                watchlist.stop_loss = stop_loss
                watchlist.is_qualified = is_qualified
                watchlist.last_updated = datetime.now()
            
            # Update progression
            if filter_progression:
                prog = watchlist.filter_progression or []
                prog.append(filter_progression)
                watchlist.filter_progression = prog
            
            # Update alerts
            if alert:
                alerts = watchlist.alert_history or []
                alerts.append(alert)
                watchlist.alert_history = alerts
            
            session.commit()
            logger.info(f"Updated watchlist for {symbol}")
    
    def get_active_watchlist(self):
        """Get all active watchlist stocks"""
        with self.session_scope() as session:
            watchlist = session.query(Watchlist)\
                .filter(Watchlist.status == 'ACTIVE')\
                .order_by(Watchlist.current_score.desc())\
                .all()
            
            return self._watchlist_to_df(watchlist)
    
    def _watchlist_to_df(self, watchlist):
        """Convert Watchlist objects to DataFrame"""
        if not watchlist:
            return pd.DataFrame()
        
        data = []
        for w in watchlist:
            data.append({
                'Symbol': w.symbol,
                'Added_Date': w.added_date,
                'Days_Tracked': (datetime.now() - w.added_date).days,
                'Filters_Passed': w.current_filters_passed,
                'Max_Filters': w.max_filters_achieved,
                'Score': w.current_score,
                'Current_Price': w.current_price,
                'Entry_Price': w.entry_price,
                'Gain_%': ((w.current_price - w.entry_price) / w.entry_price * 100) if w.entry_price else 0,
                'Stop_Loss': w.stop_loss,
                'Is_Qualified': w.is_qualified,
                'Status': w.status
            })
        
        return pd.DataFrame(data)
    
    # =====================================================
    # PRICE HISTORY OPERATIONS
    # =====================================================
    
    def save_price_data(self, symbol, df):
        """Save historical price data"""
        with self.session_scope() as session:
            count = 0
            for idx, row in df.iterrows():
                # Check if exists
                existing = session.query(PriceHistory)\
                    .filter_by(symbol=symbol, date=idx)\
                    .first()
                
                if not existing:
                    price = PriceHistory(
                        symbol=symbol,
                        date=idx,
                        open=row['Open'],
                        high=row['High'],
                        low=row['Low'],
                        close=row['Close'],
                        volume=row['Volume']
                    )
                    session.add(price)
                    count += 1
            
            if count > 0:
                logger.info(f"Saved {count} price records for {symbol}")
            return count
    
    def get_price_data(self, symbol, start_date=None, end_date=None):
        """Get historical price data for a symbol"""
        with self.session_scope() as session:
            query = session.query(PriceHistory).filter_by(symbol=symbol)
            
            if start_date:
                query = query.filter(PriceHistory.date >= start_date)
            if end_date:
                query = query.filter(PriceHistory.date <= end_date)
            
            results = query.order_by(PriceHistory.date).all()
            
            if not results:
                return pd.DataFrame()
            
            data = {
                'Open': [r.open for r in results],
                'High': [r.high for r in results],
                'Low': [r.low for r in results],
                'Close': [r.close for r in results],
                'Volume': [r.volume for r in results]
            }
            
            df = pd.DataFrame(data, index=[r.date for r in results])
            return df
    
    # =====================================================
    # ALERT OPERATIONS
    # =====================================================
    
    def create_alert(self, symbol, alert_type, severity, message, details=None):
        """Create a new trading alert"""
        with self.session_scope() as session:
            alert = TradingAlert(
                symbol=symbol,
                alert_type=alert_type,
                severity=severity,
                message=message,
                details=details or {}
            )
            session.add(alert)
            logger.info(f"Created alert: {alert_type} for {symbol}")
    
    def get_unread_alerts(self):
        """Get all unread alerts"""
        with self.session_scope() as session:
            alerts = session.query(TradingAlert)\
                .filter_by(is_read=False)\
                .order_by(TradingAlert.alert_date.desc())\
                .all()
            
            return self._alerts_to_df(alerts)
    
    def mark_alert_read(self, alert_id):
        """Mark an alert as read"""
        with self.session_scope() as session:
            alert = session.query(TradingAlert).get(alert_id)
            if alert:
                alert.is_read = True
    
    def _alerts_to_df(self, alerts):
        """Convert alerts to DataFrame"""
        if not alerts:
            return pd.DataFrame()
        
        data = []
        for a in alerts:
            data.append({
                'ID': a.id,
                'Date': a.alert_date,
                'Symbol': a.symbol,
                'Type': a.alert_type,
                'Severity': a.severity,
                'Message': a.message,
                'Is_Read': a.is_read
            })
        
        return pd.DataFrame(data)
    
    # =====================================================
    # METADATA OPERATIONS
    # =====================================================
    
    def save_scan_metadata(self, scan_type, start_time, end_time, stats, 
                          market_regime, config_snapshot, status='SUCCESS', error_msg=None):
        """Save scan execution metadata"""
        with self.session_scope() as session:
            duration = (end_time - start_time).total_seconds()
            
            metadata = ScanMetadata(
                scan_date=start_time,
                scan_type=scan_type,
                start_time=start_time,
                end_time=end_time,
                duration_seconds=duration,
                total_stocks_scanned=stats.get('total_scanned', 0),
                qualified_stocks=stats.get('qualified', 0),
                watchlist_additions=stats.get('watchlist_added', 0),
                alerts_generated=stats.get('alerts_generated', 0),
                market_regime=market_regime,
                config_snapshot=config_snapshot,
                status=status,
                error_message=error_msg
            )
            session.add(metadata)
            logger.info(f"Saved scan metadata: {scan_type}")
    
    def get_scan_history(self, limit=10):
        """Get recent scan execution history"""
        with self.session_scope() as session:
            metadata = session.query(ScanMetadata)\
                .order_by(ScanMetadata.scan_date.desc())\
                .limit(limit)\
                .all()
            
            if not metadata:
                return pd.DataFrame()
            
            data = []
            for m in metadata:
                data.append({
                    'Scan_Date': m.scan_date,
                    'Type': m.scan_type,
                    'Duration_Sec': m.duration_seconds,
                    'Stocks_Scanned': m.total_stocks_scanned,
                    'Qualified': m.qualified_stocks,
                    'Watchlist_Added': m.watchlist_additions,
                    'Alerts': m.alerts_generated,
                    'Market_Regime': m.market_regime,
                    'Status': m.status
                })
            
            return pd.DataFrame(data)
    
    # =====================================================
    # UTILITY METHODS
    # =====================================================
    
    def export_to_csv(self, table_name, filepath):
        """Export a table to CSV"""
        with self.session_scope() as session:
            if table_name == 'scan_results':
                df = self.get_latest_scan_results()
            elif table_name == 'watchlist':
                df = self.get_active_watchlist()
            elif table_name == 'alerts':
                df = self.get_unread_alerts()
            else:
                raise ValueError(f"Unknown table: {table_name}")
            
            df.to_csv(filepath, index=False)
            logger.info(f"Exported {table_name} to {filepath}")
            return filepath
    
    def cleanup_old_data(self, days_to_keep=90):
        """Remove old scan results and price data"""
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        with self.session_scope() as session:
            # Clean scan results
            deleted_scans = session.query(ScanResult)\
                .filter(ScanResult.scan_date < cutoff_date)\
                .delete()
            
            # Clean price history
            deleted_prices = session.query(PriceHistory)\
                .filter(PriceHistory.date < cutoff_date)\
                .delete()
            
            logger.info(f"Cleaned up {deleted_scans} old scan results and {deleted_prices} price records")
            return deleted_scans + deleted_prices
